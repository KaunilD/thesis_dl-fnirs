##### Experiment: 007


| hyp-params    | value                    |
| :------------ | ------------------------ |
| epochs        | 60                      |
| loss          | MSE |
| optimizer     | SGD                   |
| learning rate | 0.001                    |
| accuracy      | MSE            |
| momentum | 0.7 |

##### Model: 3D CNN

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv3d-1        [-1, 5, 160, 5, 22]              10
            Conv3d-2         [-1, 1, 80, 2, 11]               6
           Dropout-3                  [-1, 200]               0
            Linear-4                    [-1, 3]             603
           Dropout-5                    [-1, 3]               0
           Sigmoid-6                    [-1, 3]               0
================================================================
Total params: 619
Trainable params: 619
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.07
Forward/backward pass size (MB): 0.69
Params size (MB): 0.00
Estimated Total Size (MB): 0.76
----------------------------------------------------------------
```

##### Data

| value                                                        | param              |
| ------------------------------------------------------------ | :----------------- |
| 160                                                          | timesteps          |
| none                                                         | normalization      |
| only session 1 from [mindfulness/benchmark_tasks/fNIRS_Data](https://github.com/lmhirshf/mindfulness/tree/master/benchmark_tasks/data/fNIRS_Data) and [Experiments/Experiment7000/](https://github.com/lmhirshf/Experiments/Experiment7000/) | source experiments |
| regression; default3                                         | label type         |
| [ wm, a, v ] => [off = 0, low = 1, high = 2]                 | label config       |

##### Training

```
Epoch   Train Loss      Validation Loss
0       1.34648         1.23879
1       1.33411         1.21062
2       1.29829         1.21484
3       1.29186         1.23342
4       1.29524         1.23115
5       1.29797         1.22866
6       1.30117         1.21703
7       1.29663         1.21243
8       1.31897         1.23794
9       1.29465         1.24890
10      1.31414         1.20151
11      1.31422         1.22043
12      1.28256         1.21859
13      1.28019         1.22508
14      1.28241         1.21036
15      1.29724         1.25251
16      1.28371         1.22006
17      1.29117         1.22874
18      1.29627         1.22777
19      1.27900         1.21169
20      1.28454         1.22626
21      1.28277         1.22249
22      1.29230         1.23665
23      1.28028         1.23876
24      1.30342         1.25340
25      1.26599         1.22446
26      1.26198         1.21737
27      1.27821         1.23419
28      1.28498         1.22026
29      1.26159         1.22701
30      1.24917         1.22611
31      1.28961         1.23917
32      1.28288         1.24014
33      1.27569         1.22375
34      1.29057         1.21839
35      1.29779         1.21530
36      1.25431         1.21398
37      1.26641         1.21990
38      1.29438         1.21100
39      1.27668         1.21370
40      1.28479         1.21627
41      1.28436         1.23707
42      1.28955         1.21375
43      1.29543         1.21312
44      1.28935         1.22055
45      1.25135         1.21986
46      1.30474         1.21895
47      1.28303         1.21667
48      1.28860         1.21448
49      1.25118         1.23741
50      1.26059         1.21442
51      1.29528         1.24003
52      1.28116         1.22053
53      1.26597         1.22809
54      1.26972         1.21411
55      1.28120         1.23259
56      1.24838         1.23858
57      1.26271         1.26782
58      1.25449         1.21836
59      1.28004         1.23132
60      1.30318         1.22168
```

##### Observations

1. network is having difficulty digesting data. need to increase params / limit dropout.