##### Experiment: 002


| hyp-params    | value                    |
| :------------ | ------------------------ |
| epochs        | 30                       |
| loss          | MultiLabelSoftMarginLoss |
| optimizer     | Adam                     |
| learning rate | 0.001                    |

##### Model: 3D CNN

``` 
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv3d-1          [-1, 5, 5, 22, 1]             405
            Conv3d-2          [-1, 2, 2, 11, 1]              12
            Conv3d-3           [-1, 1, 1, 5, 1]               3
            Linear-4                   [-1, 12]              72
           Sigmoid-5                   [-1, 12]               0
================================================================
Total params: 492
Trainable params: 492
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.03
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 0.04
----------------------------------------------------------------
```

##### Data

| param              | value                                                        |
| :----------------- | ------------------------------------------------------------ |
| timesteps          | 80                                                           |
| normalization      | none                                                         |
| source experiments | only session 1 from [mindfulness/benchmark_tasks/fNIRS_Data](https://github.com/lmhirshf/mindfulness/tree/master/benchmark_tasks/data/fNIRS_Data) |
| label type         | multilabel; default4                                         |
| label config       | [ wm_o, wm_l, wm_h, v_o, v_l, v_h, a_o, a_l, a_h, ewm_o, ewm_l, ewm_h ] |

##### Training

```
Epoch   Train Loss      Validation Loss Validation Acc
0       400.99282       24.43952        58.974
1       377.34554       24.41731        58.974
2       375.86182       24.41520        58.974
3       375.54946       24.41491        58.974
4       375.46454       24.41351        58.974
5       375.42875       24.40973        58.974
6       375.68230       24.40721        58.974
7       375.42450       24.40874        58.974
8       375.43382       24.41228        58.974
9       375.40853       24.41334        58.974
10      375.39877       24.41114        58.974
11      375.40047       24.41062        58.974
12      375.39585       24.40613        58.974
13      375.41171       24.40920        58.974
14      375.85331       24.43436        25.641
15      375.45672       24.40614        56.410
16      375.26828       24.46473        48.718
17      375.33301       24.41268        53.846
18      375.34954       24.39549        56.410
19      375.36355       24.50497        46.154
20      375.29211       24.39294        53.846
21      375.19336       24.38554        58.974
22      375.25713       24.43516        51.282
23      375.24828       24.44730        48.718
24      375.19716       24.45827        48.718
25      375.17493       24.39818        53.846
26      375.28072       24.44334        48.718
27      375.32667       24.46059        46.154
28      375.13606       24.57732        30.769
29      375.15558       24.46979        48.718
30      375.08006       24.50572        43.590
```

