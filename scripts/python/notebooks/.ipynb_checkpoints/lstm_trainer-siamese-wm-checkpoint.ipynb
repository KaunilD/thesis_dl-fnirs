{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from random import shuffle, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMValDataLoader(torch_data.Dataset):\n",
    "    def __init__(self, data_list ):\n",
    "        self.data_list = data_list\n",
    "        self.image_list, self.label_list, self.class_list = [], [], []\n",
    "        self.read_lists()\n",
    "\n",
    "    def read_lists(self):\n",
    "        \n",
    "        for idx, item in enumerate(self.data_list):\n",
    "            print(idx, end=\"\\r\")\n",
    "            datum = item\n",
    "            im1 = datum[\"t1\"][0]\n",
    "            im2 = datum[\"t2\"][0]\n",
    "            im3 = datum[\"t3\"][0]\n",
    "            im4 = datum[\"t4\"][0]\n",
    "            #image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2], image.shape[3] ))\n",
    "            self.image_list.append((im1, im2, im3, im4))\n",
    "        print()\n",
    "    def __getitem__(self, index):\n",
    "        return self.image_list[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "class LSTMTrainDataLoader(torch_data.Dataset):\n",
    "    def __init__(self, master_data_list, count=1000 ):\n",
    "        self.master_data_list = master_data_list\n",
    "        self.count = count\n",
    "        self.data_list = sample(self.master_data_list[0], self.count) + sample(self.master_data_list[1], self.count)\n",
    "        shuffle(self.data_list)\n",
    "        self.image_list, self.label_list = [], []\n",
    "        self.read_lists()\n",
    "\n",
    "    def read_lists(self):\n",
    "        switch = True\n",
    "\n",
    "        for idx, item in enumerate(self.data_list):\n",
    "            print(idx, end=\"\\r\")\n",
    "            datum = np.load(item)\n",
    "            im1 = datum[0][0]\n",
    "            im2 = datum[1][0]\n",
    "            \n",
    "            #image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2], image.shape[3] ))\n",
    "            label = datum[2]\n",
    "            \n",
    "            self.image_list.append((im1, im2))\n",
    "            self.label_list.append(label)\n",
    "            \n",
    "            del im1\n",
    "            del im2\n",
    "        print()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return tuple([self.image_list[index], self.label_list[index]])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def shuffle_dataset(self):\n",
    "        del self.image_list\n",
    "        del self.label_list\n",
    "        \n",
    "        self.image_list, self.label_list = [], []\n",
    "        self.data_list = sample(self.master_data_list[0], self.count) + sample(self.master_data_list[1], self.count)\n",
    "        shuffle(self.data_list)\n",
    "        \n",
    "        self.read_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list_0 = glob.glob('C://Users//dhruv//Development//git//thesis_dl-fnirs//data//multilabel//all//mindfulness/siamese/wm/train/0/*.npy')\n",
    "train_data_list_1 = glob.glob('C://Users//dhruv//Development//git//thesis_dl-fnirs//data//multilabel//all//mindfulness/siamese/wm/train/1/*.npy')\n",
    "\n",
    "test_data_list_0 = glob.glob('C://Users//dhruv//Development//git//thesis_dl-fnirs//data//multilabel//all//mindfulness/siamese/wm/test/0/*.npy')\n",
    "test_data_list_1 = glob.glob('C://Users//dhruv//Development//git//thesis_dl-fnirs//data//multilabel//all//mindfulness/siamese/wm/test/1/*.npy')\n",
    "\n",
    "\n",
    "val_data_list = np.load('C://Users//dhruv//Development//git//thesis_dl-fnirs//data//multilabel//all//mindfulness//siamese/wm/validation/data_siamese_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = LSTMTrainDataLoader(\n",
    "    {0: train_data_list_0, 1: train_data_list_1}, count=140\n",
    ")\n",
    "print(\"Train dataset loaded.\")\n",
    "\n",
    "test_dataloader = LSTMTrainDataLoader(\n",
    "    {0: test_data_list_0, 1: test_data_list_1}, count=30\n",
    ")\n",
    "print(\"Test dataset loaded.\")\n",
    "\n",
    "val_dataloader = LSTMValDataLoader(\n",
    "    val_data_list\n",
    ")\n",
    "print(\"Validation dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset_loader, epoch, device, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    for i , (data, target) in enumerate(dataset_loader):\n",
    "\n",
    "        print('Train: [Batch: {} ({:.0f}%)]'\n",
    "              .format(\n",
    "                  i + 1,\n",
    "                  (i + 1)*100/len(dataset_loader)\n",
    "              ), end='\\r')\n",
    "        \n",
    "        labels = target.long()\n",
    "        input1, input2 = data[0].float(), data[1].float() \n",
    "        input1, input2, labels = input1.to(device), input2.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # out1, out2\n",
    "        outputs = model(input1, input2)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "\n",
    "    return running_loss/total\n",
    "\n",
    "\n",
    "def test(model, dataset_loader, device, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i , (data, target) in enumerate(dataset_loader):\n",
    "\n",
    "        print('Test: [Batch: {} ({:.0f}%)]'\n",
    "              .format(\n",
    "                  i + 1,\n",
    "                  (i + 1)*100/len(dataset_loader)\n",
    "              ), end='\\r')\n",
    "        \n",
    "        labels = target.long()\n",
    "        input1, input2 = data[0].float(), data[1].float() \n",
    "        input1, input2, labels = input1.to(device), input2.to(device), labels.to(device)\n",
    "        \n",
    "        # out1, out2\n",
    "        outputs = model(input1, input2)\n",
    "        \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        \n",
    "        correct += (pred == labels).sum()\n",
    "        \n",
    "        \"\"\"\n",
    "        print(outputs)\n",
    "        print(pred)\n",
    "        print(labels)\n",
    "        print(correct)\n",
    "        \"\"\"\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss/total, 100*correct/total\n",
    "\n",
    "\n",
    "def validate(model, dataset_loader, device, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataset_loader):\n",
    "            print('Validation: [Batch: {} ({:.0f}%)]'\n",
    "                  .format(\n",
    "                      i + 1,\n",
    "                      (i + 1)*100/len(dataset_loader)\n",
    "                  ), end='\\r')\n",
    "\n",
    "            \n",
    "            input1, input2, input3, input4 = data[0].float(), data[1].float(), data[2].float(), data[3].float()\n",
    "            input1, input2, input3, input4 = input1.to(device), input2.to(device), input3.to(device), input4.to(device)\n",
    "\n",
    "            output1 = model(input1, input2)\n",
    "            output2 = model(input1, input3)\n",
    "            output3 = model(input1, input4)\n",
    "            \n",
    "            greater_mask = output3[:, 0].gt(output1[:, 0]).cpu().numpy() & output3[:, 0].gt(output2[:, 0]).cpu().numpy()\n",
    "                \n",
    "            \"\"\"\n",
    "            valid_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \"\"\"\n",
    "            total += input1.size(0)\n",
    "            correct += np.sum(greater_mask)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class ConvLSTMNet(nn.Module):\n",
    "    def __init__( self, num_classes = 2):\n",
    "        super(ConvLSTMNet, self).__init__()\n",
    "        \n",
    "        #self.conv3d1 = nn.Conv3d(in_channels=2, out_channels=15, kernel_size=(2, 2, 2))\n",
    "        #self.bn1 = nn.BatchNorm3d(15)\n",
    "        self.pool1 = nn.AvgPool3d((50, 1, 1))\n",
    "        \n",
    "        #self.conv3d2 = nn.Conv3d(in_channels=15, out_channels=30, kernel_size=(5, 1, 1), stride=(5, 2, 2))\n",
    "        #self.bn2 = nn.BatchNorm3d(30)\n",
    "        #self.pool2 = nn.AvgPool3d((1, 1, 1))\n",
    "        \n",
    "        \n",
    "        self.convLSTM2d1 = ConvLSTM2D((5, 11), 2, 8, 1)\n",
    "        self.convLSTM2d2 = ConvLSTM2D((5, 11), 8, 64, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(3520, 1760)\n",
    "        self.fc2 = nn.Linear(1760, 880)\n",
    "        self.fc3 = nn.Linear(880, 440)\n",
    "        self.fc4 = nn.Linear(440, 220)\n",
    "        self.fc5 = nn.Linear(220, 110)\n",
    "        self.fc6 = nn.Linear(110, 55)\n",
    "        self.fc7 = nn.Linear(55, 4)\n",
    "        self.fc8 = nn.Linear(4, 2)\n",
    "        \n",
    "        \n",
    "\n",
    "    def sub_forward(self, x, hidden_states= None):\n",
    "\n",
    "        b_idx, ts, n_ch, w, h = x.size()\n",
    "        if hidden_states:\n",
    "            self.h1, self.c1 = hidden_states\n",
    "        else:\n",
    "            self.h1, self.c1 = self.convLSTM2d1.init_hidden(batch_size=b_idx)\n",
    "            self.h2, self.c2 = self.convLSTM2d2.init_hidden(batch_size=b_idx)\n",
    "        \n",
    "        # N, C, D, H, W = 1, 1, 160, 5, 22\n",
    "        out = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        #out = self.conv3d1(out)\n",
    "        out = self.pool1(out)\n",
    "        #out = self.bn1(out)\n",
    "        \"\"\"\n",
    "        out = self.conv3d2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.bn2(out)\n",
    "        \"\"\"\n",
    "        #print(out.size())\n",
    "        # N, D, C, H, W = 1, 1, 160, 5, 22\n",
    "        out = out.permute(0, 2, 1, 3, 4)\n",
    "        for t in range(0, out.size(1)):\n",
    "            \n",
    "            self.h1, self.c1 = self.convLSTM2d1(\n",
    "                out[:, t, :, :, :], (self.h1, self.c1)\n",
    "            )\n",
    "\n",
    "            self.h2, self.c2 = self.convLSTM2d2(\n",
    "                self.h1, (self.h2, self.c2)\n",
    "            )\n",
    "\n",
    "        out = self.h2.view(self.h2.size(0), -1)\n",
    "\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.fc7(out)\n",
    "        out = self.fc8(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(self, x1, x2, hidden_states = None):\n",
    "        out1 = self.sub_forward(x1)\n",
    "        out2 = self.sub_forward(x2)\n",
    "        \n",
    "        \n",
    "        o_sum = out1+out2\n",
    "        o_sum = torch.sum(o_sum, 1)\n",
    "        \n",
    "        o_prod = out1*out2\n",
    "        o_prod = torch.sum(o_prod, 1)\n",
    "        \n",
    "        o_abs = torch.abs(out1-out2)\n",
    "        o_abs = torch.sum(o_abs, 1)\n",
    "        \n",
    "        o_sq = torch.pow(out1-out2, 2)\n",
    "        o_sq = torch.sum(o_sq, 1)\n",
    "        \n",
    "        out = torch.stack((o_sum, o_prod, o_abs, o_sq))\n",
    "        out = out.permute(1, 0)\n",
    "        out = self.fc8(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM2D(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size, input_channel, hidden_channel,\n",
    "            kernel_size, stride=1, padding=0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializations\n",
    "        :param input_size: (int, int): height, width tuple of the input\n",
    "        :param input_channel: int: number of channels of the input\n",
    "        :param hidden_channel: int: number of channels of the hidden state\n",
    "        :param kernel_size: int: size of the filter\n",
    "        :param stride: int: stride\n",
    "        :param padding: int: width of the 0 padding\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTM2D, self).__init__()\n",
    "        self.n_h, self.n_w = input_size\n",
    "        self.n_c = input_channel\n",
    "        self.hidden_channel = hidden_channel\n",
    "\n",
    "        self.conv_xi = nn.Conv2d(\n",
    "            self.n_c,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_xf = nn.Conv2d(\n",
    "            self.n_c,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_xo = nn.Conv2d(\n",
    "            self.n_c,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_xg = nn.Conv2d(\n",
    "            self.n_c,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_hi = nn.Conv2d(\n",
    "            self.hidden_channel,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_hf = nn.Conv2d(\n",
    "            self.hidden_channel,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_ho = nn.Conv2d(\n",
    "            self.hidden_channel,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_hg = nn.Conv2d(\n",
    "            self.hidden_channel,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        self.conv_hi = nn.Conv2d(\n",
    "            self.hidden_channel,\n",
    "            self.hidden_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden_states):\n",
    "        \"\"\"\n",
    "        Forward prop.\n",
    "        reference: https://arxiv.org/pdf/1506.04214.pdf (3.1)\n",
    "        :param x: input tensor of shape (n_batch, n_c, n_h, n_w)\n",
    "        :param hidden_states: (tensor, tensor) for hidden and cell states.\n",
    "                              Each of shape (n_batch, n_hc, n_hh, n_hw)\n",
    "        :return: (hidden_state, cell_state)\n",
    "        \"\"\"\n",
    "\n",
    "        hidden_state, cell_state = hidden_states\n",
    "\n",
    "        xi = self.conv_xi(x)\n",
    "        hi = self.conv_hi(hidden_state)\n",
    "        xf = self.conv_xf(x)\n",
    "        hf = self.conv_hf(hidden_state)\n",
    "        xo = self.conv_xo(x)\n",
    "        ho = self.conv_ho(hidden_state)\n",
    "        xg = self.conv_xg(x)\n",
    "        hg = self.conv_hg(hidden_state)\n",
    "\n",
    "        i = torch.sigmoid(xi + hi)\n",
    "        f = torch.sigmoid(xf + hf)\n",
    "        o = torch.sigmoid(xo + ho)\n",
    "        g = torch.tanh(xg + hg)\n",
    "        #print(f.size(), cell_state.size(), i.size(), g.size())\n",
    "        cell_state = f * cell_state + i * g\n",
    "\n",
    "        hidden_state = o * torch.tanh(cell_state)\n",
    "\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (\n",
    "                torch.zeros(batch_size, self.hidden_channel, self.n_h, self.n_w).cuda(),\n",
    "                torch.zeros(batch_size, self.hidden_channel, self.n_h, self.n_w).cuda()\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ConvLSTMNet()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, verbose=True)\n",
    "    epochs = 30\n",
    "    curr_epoch = 0\n",
    "\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "\n",
    "    train_loss_history, test_loss_history = [], []\n",
    "    test_acc_history, val_acc_history = [], []\n",
    "    \n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    best_model = -1\n",
    "\n",
    "    MODEL_PATH_PREFIX = 'model-convlstm-epoch'\n",
    "    MODEL_PATH_EXT = 'pth'\n",
    "\n",
    "    train_loader = torch_data.DataLoader(\n",
    "        train_dataloader,\n",
    "        batch_size=25, shuffle=True, num_workers=0\n",
    "    )\n",
    "    \n",
    "    test_loader = torch_data.DataLoader(\n",
    "        test_dataloader,\n",
    "        batch_size=12, shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    val_loader = torch_data.DataLoader(\n",
    "        val_dataloader,\n",
    "        batch_size=16, shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    \n",
    "    is_best = True\n",
    "    best_score = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    \n",
    "    print(\"Epoch\\tTrain Loss\\tTest Loss\\tTest Accuracy\\tValidation Accuracy\")\n",
    "    while curr_epoch <= epochs:\n",
    "        \n",
    "        train_running_loss = train(\n",
    "            model, train_loader,\n",
    "            curr_epoch, device, optimizer, criterion\n",
    "        )\n",
    "        #break\n",
    "    \n",
    "        test_running_loss, test_accuracy = test(\n",
    "            model, test_loader,\n",
    "            device, criterion\n",
    "        )\n",
    "        \n",
    "        val_accuracy = validate(\n",
    "            model, val_loader,\n",
    "            device, criterion\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_accuracy)\n",
    "        # record all the models that we have had so far.\n",
    "        train_loss_history.append(\n",
    "            train_running_loss\n",
    "        )\n",
    "\n",
    "        test_acc_history.append(\n",
    "            test_accuracy\n",
    "        )\n",
    "        \n",
    "        test_loss_history.append(\n",
    "            test_running_loss\n",
    "        )\n",
    "        \n",
    "        val_acc_history.append(\n",
    "            val_accuracy\n",
    "        )\n",
    "        # write model to disk.\n",
    "\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "            \n",
    "        'models/model-lenet-epoch'\n",
    "        torch.save(\n",
    "            state,\n",
    "            MODEL_PATH_PREFIX + '-{}.'.format(curr_epoch) + MODEL_PATH_EXT\n",
    "        )\n",
    "\n",
    "        print('{}\\t{:.5f}\\t\\t{:.5f}\\t\\t{:.5f}\\t\\t{:.5f}\\t\\t'.format(\n",
    "            curr_epoch,\n",
    "            train_running_loss,\n",
    "            test_running_loss,\n",
    "            test_accuracy,\n",
    "            val_accuracy\n",
    "        ))\n",
    "        curr_epoch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_path = 'model-convlstm-epoch-18.pth'\n",
    "model = ConvLSTMNet()\n",
    "model.load_state_dict(torch.load(model_path)[\"model\"])\n",
    "model.eval()\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "true = []\n",
    "pred = []\n",
    "for data, lab in test_dataloader:\n",
    "    x1 = data[0]\n",
    "    x2 = data[1]\n",
    "    x1 = torch.from_numpy(np.array([x1])).float()\n",
    "    x2 = torch.from_numpy(np.array([x2])).float()\n",
    "    out = model(x1, x2)\n",
    "\n",
    "    #0 = matching, 1 = different\n",
    "    match = torch.max(out.data,  1)[1].numpy()[0]\n",
    "    true.append(lab)\n",
    "    pred.append(match)\n",
    "    #print(lab, \"match\" if match == 0 else \"different\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "cnf = confusion_matrix(y_pred=pred, y_true=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=[0, 1], yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(true, pred,  classes=[\"0\", \"1\"], normalize=True,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 && 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
