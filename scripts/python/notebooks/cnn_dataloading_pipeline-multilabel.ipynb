{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import tables\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Trevor Jordan Grant.\n",
    "\"\"\"\n",
    "cog_load_label_dict = {\n",
    "                       \"nb\": {\n",
    "                              \"default4\": [\"high\", \"off\", \"low\", \"off\"],\n",
    "                              \"default3\": [\"high\", \"low\", \"off\"],\n",
    "                              # Add new labels for n-back task here:\n",
    "                             },\n",
    "                       \"anb\": {\n",
    "                               \"default4\": [\"high\", \"off\", \"off\", \"low\"],\n",
    "                               \"default3\": [\"high\", \"off\", \"low\"],\n",
    "                              },\n",
    "                       \"ewm\": {\n",
    "                               \"default4\": [\"low\", \"off\", \"high\", \"off\"],\n",
    "                               \"default3\": [\"low\", \"high\", \"off\"]\n",
    "                              },\n",
    "                        \"cr\": {\n",
    "                               \"default4\": [\"off\", \"off\", \"off\", \"off\"],\n",
    "                               \"default3\": [\"off\", \"off\", \"off\"],\n",
    "                              },\n",
    "                        \"rt\": {\n",
    "                               \"default4\": [\"off\", \"off\", \"low\", \"off\"],\n",
    "                               \"default3\": [\"off\", \"low\", \"off\"],\n",
    "                              }\n",
    "                      }\n",
    "\n",
    "\n",
    "def strings_to_vectors(string_labels, as_list=False):\n",
    "    \"\"\"Maps strings in dict to interger values.\n",
    "    Args:\n",
    "        string_labels(list): The string label value of load.\n",
    "        as_list(bool): False, if True, return list instead of np.array()\n",
    "    Returns:\n",
    "        labels as np.array()\n",
    "    \"\"\"\n",
    "\n",
    "    maps = {\n",
    "            \"off\": [1, 0, 0],\n",
    "            \"low\": [0, 1, 0],\n",
    "            \"high\": [0, 0, 1],\n",
    "           }\n",
    "\n",
    "    if as_list:\n",
    "        return [maps[label] for label in string_labels]\n",
    "    return np.array([maps[label] for label in string_labels])\n",
    "\n",
    "\n",
    "def return_label(task, label_type=\"default4\", as_strings=False):\n",
    "    \"\"\"Returns a label from the cog_load_label_dict.\n",
    "    Args:\n",
    "        task(str): The task label from the coditions file.\n",
    "        label_type(string): The label schema used for the model.\n",
    "        as_strings(bool): False, if True, return string (in list) values instead.\n",
    "    Returns:\n",
    "        labels(np.array): Under defaults labels will be returned as interger\n",
    "        values in a np.array().\n",
    "    \"\"\"\n",
    "    if as_strings:\n",
    "        return cog_load_label_dict[task][label_type]\n",
    "    return np.hstack(strings_to_vectors(cog_load_label_dict[task][label_type]))\n",
    "\n",
    "#return_label(\"rt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_52_mat = {\n",
    "           1:[0,1],  2:[0,2],  3:[0,3],  4:[0,4],  5:[0,5],  6:[0,6],  7:[0,7],  8:[0,8],  9:[0,9], 10:[0,10], \n",
    "11:[1,0], 12:[1,1], 13:[1,2], 14:[1,3], 15:[1,4], 16:[1,5], 17:[1,6], 18:[1,7], 19:[1,8], 20:[1,9], 21:[1,10], \n",
    "          22:[2,1], 23:[2,2], 24:[2,3], 25:[2,4], 26:[2,5], 27:[2,6], 28:[2,7], 29:[2,8], 30:[2,9], 31:[2,10], \n",
    "32:[3,0], 33:[3,1], 34:[3,2], 35:[3,3], 36:[3,4], 37:[3,5], 38:[3,6], 39:[3,7], 40:[3,8], 41:[3,9], 42:[3,10], \n",
    "          43:[4,1], 44:[4,2], 45:[4,3], 46:[4,4], 47:[4,5], 48:[4,6], 49:[4,7], 50:[4,8], 51:[4,9], 52:[4,10]\n",
    "}\n",
    "\n",
    "def get_52_mat(data):\n",
    "    # returns a matrix of size 5x11.\n",
    "    mat = np.zeros((5, 11))\n",
    "    for idx, i in enumerate((data)):\n",
    "        loc = channel_52_mat[idx+1]\n",
    "        mat[loc[0], loc[1]] = i\n",
    "    return mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = glob.glob('../../../../../grad_school/thesis/data/mindfulness/benchmark_tasks/data/fNIRS_Data/*_conditions*')\n",
    "data = glob.glob('../../../../../grad_school/thesis/data/working_memory_fnirs/data/preprocessed/mat/mindfulness/*.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_length = 60\n",
    "multilabel_data = []\n",
    "for idx, (cond, dat) in enumerate(zip(conditions, data)):\n",
    "    c_data = pd.read_csv(cond)\n",
    "    m_data = loadmat(dat)\n",
    "    \n",
    "    \n",
    "    oxyDaya = m_data['nirs_data'][0][0][0]\n",
    "    dxyData = m_data['nirs_data'][0][0][1]\n",
    "    \n",
    "    # iterate through all the tasks here now.\n",
    "    for idx, key in enumerate(list(c_data.keys())):\n",
    "        if 'Task' in key:\n",
    "            # no gng labels\n",
    "            if c_data[key][2] in [\"gng\", \"es\"]:\n",
    "                continue\n",
    "            # get start and end index of the task\n",
    "            # cap the length of the sequence to 100.\n",
    "            start = int(c_data[key][0])\n",
    "            end = start + min(int(c_data[key][1]), time_series_length)\n",
    "            if end - start != time_series_length:\n",
    "                continue\n",
    "            # visualize heatmap: \n",
    "            # sns.heatmap(get_52_mat(oxyDaya[0]))\n",
    "            \n",
    "            oxy_series = oxyDaya[start:end, :]\n",
    "            dxy_series = dxyData[start:end, :]\n",
    "            \n",
    "            # a 100x5x22 list\n",
    "            oxy_dxy_series_mat = np.zeros((time_series_length, 5, 22))\n",
    "            \n",
    "            for ts, (oxy_slice, dxy_slice) in enumerate(zip(oxy_series, dxy_series)):\n",
    "                oxy_slice = get_52_mat(oxy_slice)\n",
    "                dxy_slice = get_52_mat(dxy_slice)\n",
    "            \n",
    "                oxy_dxy_series_mat[ts] = np.hstack([oxy_slice, dxy_slice])\n",
    "            \n",
    "            multilabel_data.append(\n",
    "                [\n",
    "                    np.asarray(oxy_dxy_series_mat), \n",
    "                    np.asarray(return_label(c_data[key][2]))\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    write data to disk\n",
    "\"\"\"\n",
    "for idx, (data, label) in enumerate(multilabel_data[0:601]):\n",
    "    np.save(\"C:\\\\Users\\\\dhruv\\\\Development\\\\git\\\\thesis_dl-fnirs\\\\data\\\\multilabel\\\\train\\\\\" + str(idx), np.asarray([data, label]))\n",
    "    \n",
    "\n",
    "for idx, (data, label) in enumerate(multilabel_data[601:]):\n",
    "    np.save(\"C:\\\\Users\\\\dhruv\\\\Development\\\\git\\\\thesis_dl-fnirs\\\\data\\\\multilabel\\\\val\\\\\" + str(idx), np.asarray([data, label]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
